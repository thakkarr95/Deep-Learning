{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raj_Thakkar_Deep_Learning_Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyHkNqe_Nytm",
        "colab_type": "code",
        "outputId": "28d4bf7f-eac4-4a6e-fc6c-12c6dd18e797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Loading Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak6dD3vz8shq",
        "colab_type": "text"
      },
      "source": [
        "# Problem 1: Speech Denoising Using 1D CNN [5 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbXLKc7k9N-9",
        "colab_type": "text"
      },
      "source": [
        "## Like you did in homework 1 Q2, install/load librosa. Take the magnitude spectrograms of the dirty signal and the clean signal |X| and |S|."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5JSnqIf8kYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the required libraries and data\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "s, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_dirty_male.wav', sr=None)\n",
        "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "y_train = np.transpose(np.abs(S))\n",
        "X_train = np.transpose(np.abs(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdLCSzBB803x",
        "colab_type": "code",
        "outputId": "df1f369b-746c-4f67-9678-c3d2418135c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2459, 513, 1)\n",
            "(2459, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y3fCTb7FKuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: \n",
        "# 1. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/\n",
        "## 2. https://www.kaggle.com/agrigorev/tensorflow-starter-conv1d-embeddings-0-442-lb - \n",
        "## 3. https://burakhimmetoglu.com/2017/08/22/time-series-classification-with-tensorflow/ - conv1d example \n",
        "# 4. https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf\n",
        "\n",
        "\n",
        "\n",
        "def conv1d(X_input, no_of_filters, filter_size, padding = \"same\", layer_name = \"\", activation_function = \"relu\"):\n",
        "\n",
        "  if activation_function == \"relu\":\n",
        "    activation = tf.nn.relu\n",
        "  elif activation_function == \"elu\":\n",
        "    activation = tf.nn.elu\n",
        "  \n",
        "  with tf.variable_scope(layer_name) as scope:\n",
        "    output = tf.layers.conv1d(inputs = X_input,\n",
        "                              filters = no_of_filters,\n",
        "                              kernel_size = filter_size,\n",
        "                              padding=padding,\n",
        "                              activation = activation\n",
        "                              )\n",
        "    return output\n",
        "\n",
        "\n",
        "def fully_connected_layer(X_input, no_of_units, layer_name,  batch_norm, training, activation_function):\n",
        "  with tf.name_scope(layer_name):\n",
        "    no_of_inputs = int(X_input.shape[1])\n",
        "    '''Using a truncated normal distribution rather than a regular normal\n",
        "       distribution ensures that there won’t be any large weights, which\n",
        "       could slow down training.\n",
        "    '''\n",
        "    # Initializing weights using Xavier initialization strategy to avoid the issue of vanishing gradients\n",
        "    # Reference page 278 of Hands-on Machine Learning with scikit-learn and TensorFlow book\n",
        "    variance = 2/(no_of_inputs+no_of_units)\n",
        "    random_values = tf.truncated_normal((no_of_inputs, no_of_units), \n",
        "                                        stddev=np.sqrt(variance))\n",
        "    print(\"stddev used is:\",np.sqrt(variance))\n",
        "    weights = tf.Variable(random_values, name = \"weights\")\n",
        "    biases = tf.Variable(tf.ones([no_of_units])*0.01, name = \"biases\")\n",
        "    output = biases + tf.matmul(X_input,weights) \n",
        "\n",
        "    # Impemented batch_nomralization using the reference https://medium.com/@jaynilbvb/implementing-batch-normalization-in-tensorflow-db3784f61693\n",
        "    if batch_norm:\n",
        "      batchNorm = tf.layers.batch_normalization(output, training=training, momentum=0.99)\n",
        "    else:\n",
        "      batchNorm = output\n",
        "          \n",
        "    if activation_function == \"relu\":\n",
        "      return tf.nn.relu(batchNorm)\n",
        "    elif activation_function == \"elu\":\n",
        "      return tf.nn.elu(batchNorm)\n",
        "    elif activation_function == \"leaky_relu\":\n",
        "      return leaky_relu(batchNorm)\n",
        "    else:\n",
        "      return output\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwU_tTXnQxgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the parameters to be used for defining the CNN\n",
        "n_inputs = X_train.shape[1] # This is the width\n",
        "height = 1 # Defining height\n",
        "n_output_dimension = y_train.shape[1]\n",
        "n_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Rr_fOISyar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the structure of X and y\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs, n_channels), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, n_output_dimension), name=\"y\")\n",
        "\n",
        "# Drop our prob and learning_rate for Optimizer\n",
        "dropout_prob = 0.9\n",
        "learning_rate = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9XLt1RdBV3k",
        "colab_type": "code",
        "outputId": "86fdf975-291e-4b8f-ad34-a3c2b27ff5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# Defining the model\n",
        "# (batch,513,1) -> (batch,257,18)\n",
        "\n",
        "# (batch,513,1) -> (batch,513,18)\n",
        "convolution_layer_1 = conv1d(X, no_of_filters = 18, filter_size = 2, \n",
        "                             padding = \"valid\", layer_name = \"convolution_layer_1\",\n",
        "                             activation_function = \"relu\")\n",
        "# max_pooling_layer_1 = tf.layers.max_pooling1d(inputs=convolution_layer_1, pool_size=2, strides=2, padding='same')\n",
        "\n",
        "# (batch,257,18) -> (batch,129,36)\n",
        "\n",
        "# (batch,513,18) -> (batch,257,36)\n",
        "convolution_layer_2 = conv1d(convolution_layer_1, no_of_filters = 36, filter_size = 2, \n",
        "                             padding = \"valid\", layer_name = \"convolution_layer_2\", \n",
        "                             activation_function = \"relu\")\n",
        "max_pooling_layer_2 = tf.layers.max_pooling1d(inputs=convolution_layer_2, \n",
        "                                              pool_size=2, strides=2, padding='valid')\n",
        "\n",
        "# (batch,129,36) -> (batch,65,72)\n",
        "\n",
        "# (batch,257,36) -> (batch,129,72)\n",
        "# convolution_layer_3 = conv1d(max_pooling_layer_2, no_of_filters = 72, filter_size = 2, padding = \"same\", layer_name = \"convolution_layer_3\", activation_function = \"relu\")\n",
        "# max_pooling_layer_3 = tf.layers.max_pooling1d(inputs=convolution_layer_3, pool_size=2, strides=2, padding='same')\n",
        "\n",
        "# (batch,65,72) -> (batch,33,144)\n",
        "# convolution_layer_4 = conv1d(max_pooling_layer_3, no_of_filters = 144, filter_size = 2, padding = \"same\", layer_name = \"convolution_layer_4\", activation_function = \"relu\")\n",
        "# max_pooling_layer_4 = tf.layers.max_pooling1d(inputs=convolution_layer_4, pool_size=2, strides=2, padding='same')\n",
        "\n",
        "flattened_max_pooling_layer_4_output = tf.layers.flatten(max_pooling_layer_2)\n",
        "flattened_max_pooling_layer_4_output = tf.nn.dropout(flattened_max_pooling_layer_4_output, keep_prob=dropout_prob)\n",
        "\n",
        "\n",
        "output_layer = fully_connected_layer(flattened_max_pooling_layer_4_output, n_output_dimension, \n",
        "                                     \"fully_connected_output_layer\", batch_norm = False, training = True, activation_function = \"relu\")\n",
        "\n",
        "# output_layer = tf.layers.dense(flattened_max_pooling_layer_4_output, n_output_dimension)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-f51f06a52ea2>:16: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-403033fb06a4>:13: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling1D instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-403033fb06a4>:25: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-403033fb06a4>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "stddev used is: 0.014364347119619057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJhJX6s-JZC2",
        "colab_type": "code",
        "outputId": "064a8d8a-b0a1-4b69-8d60-c071e6c471b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "loss = tf.losses.mean_squared_error(labels=y,predictions=output_layer)\n",
        "loss_function = tf.reduce_mean(loss, name = 'loss_function') # use square error for cost function\n",
        "\n",
        "# Defining the Adam Optimizer we will use\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name = \"Adam-Opt\").minimize(loss_function)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ4tp_N0JcyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing all variables\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnhljXOcOwSl",
        "colab_type": "code",
        "outputId": "0daabf78-ec1d-4575-d4f7-e59194fe7a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "\n",
        "sess.run(init)\n",
        "\n",
        "convolution_layer_1_output = sess.run(convolution_layer_1, feed_dict={X: X_train, y: y_train})\n",
        "print(convolution_layer_1_output.shape)\n",
        "\n",
        "sess.close()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2459, 512, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlmD5A4EJiag",
        "colab_type": "code",
        "outputId": "83b880bc-ef48-41e2-f596-7c1d51357c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "min_loss = 0.005\n",
        "\n",
        "extra_graphkeys_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "sess = tf.InteractiveSession()\n",
        "# init.run()\n",
        "sess.run(init)\n",
        "for epoch in range(1,n_epochs+1):\n",
        "  for iteration in range(X_train.shape[0] // batch_size):\n",
        "    # X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "    # X_batch, y_batch = shuffle(X_batch, y_batch)\n",
        "\n",
        "    rand_index = np.random.choice(n_inputs, size=batch_size)\n",
        "    X_batch = X_train[rand_index,:,:] # Transpose to the correct shape\n",
        "    y_batch = y_train[rand_index,:]\n",
        "\n",
        "\n",
        "    sess.run(optimizer, feed_dict={X: X_batch, y: y_batch})\n",
        "  loss_train = sess.run(loss_function, feed_dict={X: X_batch, y: y_batch})\n",
        "  # loss_test = sess.run(loss_function, feed_dict={X: X_test, y: y_test})\n",
        "  if loss_train < min_loss:\n",
        "    min_loss = loss_train\n",
        "    print(\"Lowest train loss achieved till now!\")\n",
        "    save_path = saver.save(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\")\n",
        "    print(\"Epoch:\",epoch, \"Train loss:\", loss_train)\n",
        " \n",
        "  else:\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch:\",epoch, \"Train loss:\", loss_train)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lowest train loss achieved till now!\n",
            "Epoch: 24 Train loss: 0.004805775\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 25 Train loss: 0.0038954825\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 31 Train loss: 0.0037945984\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 36 Train loss: 0.0037513534\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 37 Train loss: 0.0028538664\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 39 Train loss: 0.0026633993\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 47 Train loss: 0.0025643855\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 49 Train loss: 0.0020939447\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 53 Train loss: 0.002023547\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 57 Train loss: 0.0019493065\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 64 Train loss: 0.0018172745\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 66 Train loss: 0.0015522727\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 74 Train loss: 0.0014223235\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 93 Train loss: 0.0013651251\n",
            "Epoch: 100 Train loss: 0.001578904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RuQSHFTL96C",
        "colab_type": "code",
        "outputId": "69a8111c-04e3-42a5-8ea9-3008abcb9a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/test_x_01.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_test_abs = np.abs(X_t)\n",
        "\n",
        "X_test = np.transpose(X_test_abs)\n",
        "\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X: X_test})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_test_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/test_s_01_1d_cnn_recons.wav', s_cap, sr)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V40KkllIMkLV",
        "colab_type": "code",
        "outputId": "c19bb875-65e4-48d6-f52b-374b1f6e8a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/test_x_02.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_test_abs = np.abs(X_t)\n",
        "\n",
        "X_test = np.transpose(X_test_abs)\n",
        "\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X: X_test})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_test_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/test_s_02_1d_cnn_recons.wav', s_cap, sr)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIDZc8WlM4cz",
        "colab_type": "code",
        "outputId": "a63f598f-774e-434a-d211-6ea050c8437f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Calculating SNR for the first input file\n",
        "\n",
        "s, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "\n",
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_dirty_male.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "y_train = np.transpose(np.abs(S))\n",
        "X_train_abs = np.abs(X_t)\n",
        "X_train = np.transpose(X_train_abs)\n",
        "\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "\n",
        "# sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_1/Problem_2/test_x_02.wav', sr=None)\n",
        "# X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# X_test_abs = np.abs(X_t)\n",
        "\n",
        "# X_test = np.transpose(X_test_abs)\n",
        "\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X: X_train})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_train_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/train_1d_cnn_recons.wav', s_cap, sr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# snr = 10*np.log10(np.sum(np.square(s))/np.sum(np.square(np.subtract(s, s_cap))))\n",
        "\n",
        "snr = 10*np.log10(np.dot(np.transpose(s),s)/np.dot(np.transpose(s-s_cap),(s-s_cap)))\n",
        "print('Signal to Noise Ratio for input file using 1D CNN is:',snr)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_1d_cnn_model.ckpt\n",
            "Signal to Noise Ratio for input file using 1D CNN is: 10.177600383758545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdOR5ak9MBzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "22bb0631-8017-4c1c-8d59-398a912d74d8"
      },
      "source": [
        "# Calculating SNR in the time domain too\n",
        "sn1, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav')\n",
        "sn2, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_1d_cnn_recons.wav')\n",
        "snr=10*np.log10( np.square(sn1).sum() / ( np.square(sn1-sn2) ).sum()  ) \n",
        "print('Signal to Noise Ratio for input file using 1D CNN is:',snr)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Signal to Noise Ratio for input file using 1D CNN is: 10.200825929641724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmdkDCwU3dSE",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2: Speech Denoising Using 2D CNN [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGTq5m8Q3ecB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the required libraries and data\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "s, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_dirty_male.wav', sr=None)\n",
        "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "y_train = np.transpose(np.abs(S))\n",
        "X_train_abs = np.abs(X)\n",
        "X_train = np.transpose(np.abs(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSYtgB54KoX",
        "colab_type": "code",
        "outputId": "e5c335de-267d-4206-a058-78468c354935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "\n",
        "for i in range(19):\n",
        "  X_train = np.insert(X_train, 0, [np.random.uniform(10**(-26), 10**(-50)) for j in range(513)], axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "X_train\n",
        "\n",
        "# X_train[2439:2459,:]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2478, 513)\n",
            "(2459, 513)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.6581788e-27, 2.6224885e-27, 8.6631723e-29, ..., 4.8300266e-27,\n",
              "        5.7060825e-27, 6.4507390e-27],\n",
              "       [4.5649867e-27, 9.4505180e-28, 2.5455057e-27, ..., 4.0531400e-27,\n",
              "        1.4274459e-27, 5.1863360e-27],\n",
              "       [5.7513299e-27, 5.3132802e-27, 9.1044039e-27, ..., 4.7512965e-27,\n",
              "        2.9762875e-27, 4.6878152e-27],\n",
              "       ...,\n",
              "       [1.5213569e-02, 1.5371690e-02, 1.3715556e-02, ..., 9.3410030e-04,\n",
              "        7.1277702e-03, 1.5927447e-03],\n",
              "       [4.9811867e-03, 1.5078177e-03, 2.2639418e-02, ..., 1.3958135e-02,\n",
              "        7.0389216e-03, 4.5577832e-04],\n",
              "       [7.7582356e-03, 2.0596350e-02, 2.8300950e-02, ..., 1.2237257e-02,\n",
              "        1.7999319e-02, 1.6074810e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJTc-Hk3_657",
        "colab_type": "text"
      },
      "source": [
        "## Therefore, a pair of adjacent images (unless you shuffe the order) will be with 19 overlapped frames. Since your original STFT spectrogram has 2,459 frames, you can create 2,440 such images as your training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdAGUGJ6AB3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_image = []\n",
        "\n",
        "# for i in range(X_train.shape[0]):\n",
        "#   temp = X_train[i:i+20,:]\n",
        "#   if len(temp) == 20:\n",
        "#     X_train_image.append(temp)\n",
        "\n",
        "# len(X_train_image)\n",
        "\n",
        "# X_train_image[2439]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "micJYGUaGzkc",
        "colab_type": "code",
        "outputId": "f320ba04-affd-4b8a-9d36-ae38fad1c70c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X_train_image = np.zeros([y_train.shape[0],20,X_train.shape[1]])\n",
        "\n",
        "for i in range(X_train.shape[0]):\n",
        "  temp = X_train[i:i+20,:]\n",
        "  if len(temp) == 20:\n",
        "    X_train_image[i,:,:] = temp\n",
        "\n",
        "len(X_train_image)\n",
        "\n",
        "X_train_image = np.reshape(X_train_image,(y_train.shape[0], 20, X_train.shape[1],1))\n",
        "X_train_image.shape\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2459, 20, 513, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGGI9Gc4OCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference 1: http://aqibsaeed.github.io/2016-11-04-human-activity-recognition-cnn/\n",
        "# Reference 2: https://www.datacamp.com/community/tutorials/cnn-tensorflow-python\n",
        "## Reference 3: https://medium.com/data-science-group-iitr/building-a-convolutional-neural-network-in-python-with-tensorflow-d251c3ca8117\n",
        "\n",
        "\n",
        "\n",
        "def conv2d(X_input, no_of_filters, filter_size, padding = \"same\", layer_name = \"\", activation_function = \"relu\"):\n",
        "\n",
        "  if activation_function == \"relu\":\n",
        "    activation = tf.nn.relu\n",
        "  elif activation_function == \"elu\":\n",
        "    activation = tf.nn.elu\n",
        "  \n",
        "  with tf.variable_scope(layer_name) as scope:\n",
        "    output = tf.layers.conv2d(inputs = X_input,\n",
        "                              filters = no_of_filters,\n",
        "                              kernel_size = filter_size,\n",
        "                              padding=padding,\n",
        "                              activation = activation\n",
        "                              )\n",
        "    return output\n",
        "\n",
        "\n",
        "def fully_connected_layer(X_input, no_of_units, layer_name,  batch_norm, training, activation_function):\n",
        "  with tf.name_scope(layer_name):\n",
        "    no_of_inputs = int(X_input.shape[1])\n",
        "    '''Using a truncated normal distribution rather than a regular normal\n",
        "       distribution ensures that there won’t be any large weights, which\n",
        "       could slow down training.\n",
        "    '''\n",
        "    # Initializing weights using Xavier initialization strategy to avoid the issue of vanishing gradients\n",
        "    # Reference page 278 of Hands-on Machine Learning with scikit-learn and TensorFlow book\n",
        "    variance = 2/(no_of_inputs+no_of_units)\n",
        "    random_values = tf.truncated_normal((no_of_inputs, no_of_units), \n",
        "                                        stddev=np.sqrt(variance))\n",
        "    print(\"stddev used is:\",np.sqrt(variance))\n",
        "    weights = tf.Variable(random_values, name = \"weights\")\n",
        "    biases = tf.Variable(tf.ones([no_of_units])*0.01, name = \"biases\")\n",
        "    output = biases + tf.matmul(X_input,weights) \n",
        "\n",
        "    # Impemented batch_nomralization using the reference https://medium.com/@jaynilbvb/implementing-batch-normalization-in-tensorflow-db3784f61693\n",
        "    if batch_norm:\n",
        "      batchNorm = tf.layers.batch_normalization(output, training=training, momentum=0.99)\n",
        "    else:\n",
        "      batchNorm = output\n",
        "          \n",
        "    if activation_function == \"relu\":\n",
        "      return tf.nn.relu(batchNorm)\n",
        "    elif activation_function == \"elu\":\n",
        "      return tf.nn.elu(batchNorm)\n",
        "    elif activation_function == \"leaky_relu\":\n",
        "      return leaky_relu(batchNorm)\n",
        "    else:\n",
        "      return output\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZJCSudkIIYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the parameters to be used for defining the neural network\n",
        "\n",
        "\n",
        "n_inputs = X_train_image.shape[2] # This is the width\n",
        "height = X_train_image.shape[1] # Defining height\n",
        "n_output_dimension = y_train.shape[1]\n",
        "n_channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwKMEw-ZH5Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Placeholder for X\n",
        "X_image = tf.placeholder(tf.float32, shape=(None, height, n_inputs, n_channels), name=\"X\")\n",
        "# Reshape the place_holder into [no_of_images, image_height, image_width, no_of_channels]\n",
        "# X_image = tf.reshape(X,[-1, height, n_inputs, n_channels])\n",
        "\n",
        "# Placeholder for y\n",
        "y = tf.placeholder(tf.float32, shape=(None, n_output_dimension), name=\"y\")\n",
        "\n",
        "# Drop our prob and learning_rate for Optimizer\n",
        "dropout_prob = 0.9\n",
        "learning_rate = 0.0002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG6sb_wDJnJb",
        "colab_type": "code",
        "outputId": "782ca2d2-bac5-4e28-e2a1-80b11cce134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# Defining the model\n",
        "\n",
        "# (batch,20,513,1) -> (batch,20,513,8)\n",
        "convolution_layer_1 = conv2d(X_image, no_of_filters = 8, filter_size = 4, \n",
        "                             padding = \"same\", layer_name = \"convolution_layer_1\",\n",
        "                             activation_function = \"relu\")\n",
        "\n",
        "# max_pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_1, \n",
        "                                              # pool_size=2, strides=2, padding='same')\n",
        "\n",
        "# (batch,20,513,8) -> (batch,10,257,16)\n",
        "convolution_layer_2 = conv2d(convolution_layer_1, no_of_filters = 16, filter_size = 2, \n",
        "                             padding = \"same\", layer_name = \"convolution_layer_2\", \n",
        "                             activation_function = \"elu\")\n",
        "max_pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_2, \n",
        "                                              pool_size=2, strides=2, padding='same')\n",
        "# (batch,10,257,16) -> (batch,5,129,32)\n",
        "convolution_layer_3 = conv2d(max_pooling_layer_2, no_of_filters = 32, filter_size = 1,\n",
        "                             padding = \"same\", layer_name = \"convolution_layer_3\",\n",
        "                             activation_function = \"elu\")\n",
        "max_pooling_layer_3 = tf.layers.max_pooling2d(inputs=convolution_layer_3, \n",
        "                                              pool_size=2, strides=2, padding='same')\n",
        "\n",
        "# (batch,65,72) -> (batch,33,144)\n",
        "# convolution_layer_4 = conv1d(max_pooling_layer_3, no_of_filters = 144, filter_size = 2, padding = \"same\", layer_name = \"convolution_layer_4\", activation_function = \"relu\")\n",
        "# max_pooling_layer_4 = tf.layers.max_pooling1d(inputs=convolution_layer_4, pool_size=2, strides=2, padding='same')\n",
        "\n",
        "flattened_max_pooling_layer_4_output = tf.reshape(max_pooling_layer_3, (-1, 5*129*32))\n",
        "flattened_max_pooling_layer_4_output = tf.nn.dropout(flattened_max_pooling_layer_4_output, keep_prob=dropout_prob)\n",
        "\n",
        "\n",
        "output_layer = fully_connected_layer(flattened_max_pooling_layer_4_output, n_output_dimension, \n",
        "                                     \"fully_connected_output_layer\", batch_norm = False, training = True, activation_function = \"relu\")\n",
        "\n",
        "# output_layer = tf.layers.dense(flattened_max_pooling_layer_4_output, n_output_dimension)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-d95e36e1fe20>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From <ipython-input-23-eb21a80ee8b1>:13: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "stddev used is: 0.00972364317089614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3WdYYS1VNb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.losses.mean_squared_error(labels=y,predictions=output_layer)\n",
        "loss_function = tf.reduce_mean(loss, name = 'loss_function') # use square error for cost function\n",
        "\n",
        "# Defining the Adam Optimizer we will use\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name = \"Adam-Opt\").minimize(loss_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5R3rBOcVQ_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing all variables\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C6RP7MEVU6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sess = tf.InteractiveSession()\n",
        "\n",
        "# sess.run(init)\n",
        "\n",
        "# convolution_layer_2_output = sess.run(max_pooling_layer_2, feed_dict={X_image: X_train_image[0:20,:,:,:], y: y_train})\n",
        "# print(convolution_layer_2_output.shape)\n",
        "\n",
        "# sess.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lbePaGwVZVM",
        "colab_type": "code",
        "outputId": "51ff701d-e330-4851-e421-2ae80352c157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "n_epochs = 1000\n",
        "batch_size = 128\n",
        "\n",
        "min_loss = 0.005\n",
        "\n",
        "extra_graphkeys_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "sess = tf.InteractiveSession()\n",
        "# init.run()\n",
        "sess.run(init)\n",
        "for epoch in range(1,n_epochs+1):\n",
        "  for offset in range(0, X_train_image.shape[0], batch_size):\n",
        "    # X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "    # X_batch, y_batch = shuffle(X_batch, y_batch)\n",
        "\n",
        "    # rand_index = np.random.choice(n_inputs, size=batch_size)\n",
        "    # rand_index = [i for i in range(iteration:iteration+batch_size)]\n",
        "    X_batch = X_train_image[offset:offset+batch_size,:,:,:] # Transpose to the correct shape\n",
        "    y_batch = y_train[offset:offset+batch_size,:]\n",
        "\n",
        "\n",
        "    sess.run(optimizer, feed_dict={X_image: X_batch, y: y_batch})\n",
        "  loss_train = sess.run(loss_function, feed_dict={X_image: X_batch, y: y_batch})\n",
        "  # loss_test = sess.run(loss_function, feed_dict={X: X_test, y: y_test})\n",
        "  if loss_train < min_loss:\n",
        "    min_loss = loss_train\n",
        "    print(\"Lowest train loss achieved till now!\")\n",
        "    save_path = saver.save(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\")\n",
        "    print(\"Epoch:\",epoch, \"Train loss:\", loss_train)\n",
        " \n",
        "  else:\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch:\",epoch, \"Train loss:\", loss_train)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lowest train loss achieved till now!\n",
            "Epoch: 9 Train loss: 0.004779021\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 10 Train loss: 0.0044362773\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 11 Train loss: 0.0041842307\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 12 Train loss: 0.0040924973\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 13 Train loss: 0.0038648536\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 15 Train loss: 0.0034482474\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 19 Train loss: 0.0034463932\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 20 Train loss: 0.0033947\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 24 Train loss: 0.0032482287\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 25 Train loss: 0.003169674\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 26 Train loss: 0.003089836\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 28 Train loss: 0.002934055\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 29 Train loss: 0.0027209613\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 32 Train loss: 0.0026845268\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 35 Train loss: 0.0026144823\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 39 Train loss: 0.0025009734\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 40 Train loss: 0.002399588\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 43 Train loss: 0.0023433417\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 50 Train loss: 0.0023385007\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 52 Train loss: 0.0023351589\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 55 Train loss: 0.00228536\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 57 Train loss: 0.0021983995\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 63 Train loss: 0.002191449\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 64 Train loss: 0.002189874\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 66 Train loss: 0.002163433\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 68 Train loss: 0.0020182976\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 74 Train loss: 0.0020111953\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 78 Train loss: 0.002000942\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 85 Train loss: 0.0019970364\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 87 Train loss: 0.0019897423\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 91 Train loss: 0.0019293649\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 92 Train loss: 0.0019212725\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 94 Train loss: 0.0018826796\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 95 Train loss: 0.0018488852\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 96 Train loss: 0.001808368\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 97 Train loss: 0.0017785119\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 99 Train loss: 0.0017478446\n",
            "Epoch: 100 Train loss: 0.0018072184\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 104 Train loss: 0.0017428896\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 109 Train loss: 0.0017325052\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 111 Train loss: 0.0017031616\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 120 Train loss: 0.0016730289\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 127 Train loss: 0.001649456\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 130 Train loss: 0.001644803\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 131 Train loss: 0.0016230532\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 139 Train loss: 0.0016063807\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 141 Train loss: 0.0016024265\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 144 Train loss: 0.0015899645\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 146 Train loss: 0.0015492984\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 155 Train loss: 0.0015322291\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 169 Train loss: 0.0015249866\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 174 Train loss: 0.0014931181\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 182 Train loss: 0.0014714875\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 195 Train loss: 0.0014434621\n",
            "Epoch: 200 Train loss: 0.0014547346\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 208 Train loss: 0.0014203175\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 213 Train loss: 0.0014199783\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 216 Train loss: 0.0014130304\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 219 Train loss: 0.0014018124\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 221 Train loss: 0.0013677481\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 225 Train loss: 0.0013390064\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 237 Train loss: 0.0013311553\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 243 Train loss: 0.0013030374\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 249 Train loss: 0.0012851644\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 251 Train loss: 0.0012671727\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 255 Train loss: 0.001256591\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 262 Train loss: 0.0012538745\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 263 Train loss: 0.0012253635\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 264 Train loss: 0.0011825756\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 296 Train loss: 0.0011791639\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 300 Train loss: 0.001173296\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 305 Train loss: 0.0011494263\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 316 Train loss: 0.001139654\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 332 Train loss: 0.0011060361\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 333 Train loss: 0.0011059603\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 358 Train loss: 0.0010817528\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 370 Train loss: 0.0010479075\n",
            "Epoch: 400 Train loss: 0.0010931422\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 412 Train loss: 0.0010438962\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 413 Train loss: 0.0010408958\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 414 Train loss: 0.001036044\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 418 Train loss: 0.001008466\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 428 Train loss: 0.0009977774\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 444 Train loss: 0.000990468\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 452 Train loss: 0.0009875491\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 458 Train loss: 0.00096654735\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 459 Train loss: 0.000944119\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 490 Train loss: 0.0009175176\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 495 Train loss: 0.00090337615\n",
            "Epoch: 500 Train loss: 0.00096555287\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 540 Train loss: 0.000894001\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 545 Train loss: 0.00088626216\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 547 Train loss: 0.00088211574\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 573 Train loss: 0.0008800182\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 575 Train loss: 0.00087653653\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 579 Train loss: 0.0008656685\n",
            "Epoch: 600 Train loss: 0.00089949416\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 609 Train loss: 0.00086231204\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 611 Train loss: 0.00085927476\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 615 Train loss: 0.0008561523\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 617 Train loss: 0.0008428801\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 637 Train loss: 0.0008234705\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 640 Train loss: 0.00082183455\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 681 Train loss: 0.0008156119\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 687 Train loss: 0.0008138573\n",
            "Epoch: 700 Train loss: 0.0008318553\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 710 Train loss: 0.00079187547\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 752 Train loss: 0.0007754392\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 778 Train loss: 0.0007544359\n",
            "Epoch: 800 Train loss: 0.0008181092\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 815 Train loss: 0.0007303179\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 867 Train loss: 0.0007218391\n",
            "Epoch: 900 Train loss: 0.00072800124\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 925 Train loss: 0.0007167654\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 931 Train loss: 0.0007094317\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 937 Train loss: 0.0006996975\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 974 Train loss: 0.0006909824\n",
            "Lowest train loss achieved till now!\n",
            "Epoch: 994 Train loss: 0.00069018523\n",
            "Epoch: 1000 Train loss: 0.0007259266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8f1fc97d-2db5-4cfd-d59e-f4a7f614d30e",
        "id": "PEYTlGu0ejnX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/test_x_01.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_test_abs = np.abs(X_t)\n",
        "\n",
        "X_test = np.transpose(X_test_abs)\n",
        "\n",
        "print(X_test.shape)\n",
        "\n",
        "for i in range(19):\n",
        "  X_test = np.insert(X_test, 0, [np.random.uniform(10**(-26), 10**(-50)) for j in range(513)], axis=0)\n",
        "\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "X_test_image = np.zeros([X_test_abs.shape[1],20,X_test_abs.shape[0]])\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  temp = X_test[i:i+20,:]\n",
        "  if len(temp) == 20:\n",
        "    X_test_image[i,:,:] = temp\n",
        "\n",
        "print(len(X_test_image))\n",
        "\n",
        "X_test_image = np.reshape(X_test_image,(X_test_abs.shape[1], 20, X_test_abs.shape[0],1))\n",
        "print(X_test_image.shape)\n",
        "\n",
        "# X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X_image: X_test_image})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_test_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/test_s_01_2d_cnn_recons.wav', s_cap, sr)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(142, 513)\n",
            "(161, 513)\n",
            "142\n",
            "(142, 20, 513, 1)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV276QLVevFd",
        "colab_type": "code",
        "outputId": "401bdfcc-e94f-4fa5-f390-fbe0707542a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/test_x_02.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_test_abs = np.abs(X_t)\n",
        "\n",
        "X_test = np.transpose(X_test_abs)\n",
        "\n",
        "print(X_test.shape)\n",
        "\n",
        "for i in range(19):\n",
        "  X_test = np.insert(X_test, 0, [np.random.uniform(10**(-26), 10**(-50)) for j in range(513)], axis=0)\n",
        "\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "X_test_image = np.zeros([X_test_abs.shape[1],20,X_test_abs.shape[0]])\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  temp = X_test[i:i+20,:]\n",
        "  if len(temp) == 20:\n",
        "    X_test_image[i,:,:] = temp\n",
        "\n",
        "print(len(X_test_image))\n",
        "\n",
        "X_test_image = np.reshape(X_test_image,(X_test_abs.shape[1], 20, X_test_abs.shape[0],1))\n",
        "print(X_test_image.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X_image: X_test_image})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_test_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/test_s_02_2d_cnn_recons.wav', s_cap, sr)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(380, 513)\n",
            "(399, 513)\n",
            "380\n",
            "(380, 20, 513, 1)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z780oNce85h",
        "colab_type": "code",
        "outputId": "b2c3cd3e-8a2c-4306-8271-eb1c88c59042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Calculating SNR for the first input file\n",
        "saver = tf.train.Saver()\n",
        "s, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "\n",
        "sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_dirty_male.wav', sr=None)\n",
        "X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# y_train = np.transpose(np.abs(S))\n",
        "# X_train_abs = np.abs(X_t)\n",
        "# X_train = np.transpose(X_train_abs)\n",
        "\n",
        "# print(X_train.shape)\n",
        "\n",
        "# X_train_image = np.zeros([X_train.shape[0],20,X_train.shape[1]])\n",
        "\n",
        "# for i in range(X_train.shape[0]):\n",
        "#   temp = X_train[i:i+20,:]\n",
        "#   if len(temp) == 20:\n",
        "#     X_train_image[i,:,:] = temp\n",
        "\n",
        "# len(X_train_image)\n",
        "\n",
        "# X_train_image = np.reshape(X_train_image,(X_train_abs.shape[1], 20, X_train_abs.shape[0],1))\n",
        "print(X_train_image.shape)\n",
        "\n",
        "# X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "\n",
        "# sn, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_1/Problem_2/test_x_02.wav', sr=None)\n",
        "# X_t=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# X_test_abs = np.abs(X_t)\n",
        "\n",
        "# X_test = np.transpose(X_test_abs)\n",
        "\n",
        "X_train_abs = np.abs(X_t)\n",
        "sess = tf.InteractiveSession()\n",
        "saver.restore(sess, \"/content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\")\n",
        "\n",
        "mod_S_test_predicted = sess.run(output_layer, feed_dict={X_image: X_train_image})\n",
        "\n",
        "sess.close()\n",
        "\n",
        "S_cap = np.multiply(np.divide(X_t,X_train_abs),np.transpose(mod_S_test_predicted))\n",
        "\n",
        "s_cap = librosa.core.istft(S_cap, hop_length=512, length=len(sn))\n",
        "\n",
        "librosa.output.write_wav('/content/drive/My Drive/Deep_Learning/Assignment_2/train_2d_cnn_recons.wav', s_cap, sr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# snr = 10*np.log10(np.sum(np.square(s))/np.sum(np.square(np.subtract(s, s_cap))))\n",
        "print(s.shape)\n",
        "print(s_cap.shape)\n",
        "snr = 10*np.log10(np.dot(np.transpose(s),s)/np.dot(np.transpose(s-s_cap),(s-s_cap)))\n",
        "print('Signal to Noise Ratio for input file using 2D CNN is:',snr)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2459, 20, 513, 1)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Deep_Learning/Assignment_2/best_audio_denoising_2d_cnn_model.ckpt\n",
            "(1258899,)\n",
            "(1258899,)\n",
            "Signal to Noise Ratio for input file using 2D CNN is: 16.21869206428528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahS2D61pl2Fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2e2068de-79d2-4be6-ad95-6ea56130fe73"
      },
      "source": [
        "# Calculating SNR in the time domain too\n",
        "sn1, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_clean_male.wav')\n",
        "sn2, sr=librosa.load('/content/drive/My Drive/Deep_Learning/Assignment_2/train_2d_cnn_recons.wav')\n",
        "snr=10*np.log10( np.square(sn1).sum() / ( np.square(sn1-sn2) ).sum()  ) \n",
        "print('Signal to Noise Ratio for input file using 2D CNN is:',snr)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Signal to Noise Ratio for input file using 2D CNN is: 16.353379487991333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}